<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>datastructures on schoettkr</title>
    <link>https://schoettkr.github.io/knowledge-database/tags/datastructures/</link>
    <description>Recent content in datastructures on schoettkr</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Apr 2019 00:00:00 +0200</lastBuildDate>
    
	<atom:link href="https://schoettkr.github.io/knowledge-database/tags/datastructures/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Datastructures - Lecture 04</title>
      <link>https://schoettkr.github.io/knowledge-database/uni/ds/04_lecture/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>https://schoettkr.github.io/knowledge-database/uni/ds/04_lecture/</guid>
      <description>Efficient Sorting Algorithms 1. Quicksort For applying the quicksort sorting algorithm we first choose a (random) pivot element (Drehpunkt/Mittelpunkt/Achse). The array gets partitioned into two virtual arrays. Virtual in this case means that the original array and the allocated memory for the original array is used for virtual subarrays. The first &amp;ldquo;subarray&amp;rdquo; holds all elements which are less than or equal to the pivot element, the other &amp;ldquo;subarray&amp;rdquo; holds all elements which are greater than or equal to the pivot element.</description>
    </item>
    
    <item>
      <title>Datastructures - Lecture 03</title>
      <link>https://schoettkr.github.io/knowledge-database/uni/ds/03_lecture/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>https://schoettkr.github.io/knowledge-database/uni/ds/03_lecture/</guid>
      <description>Simple Sorting Algorithms In this lecture we&amp;rsquo;re looking at simple array sorting algorithms. There are multiple criteria for judging an (sorting) algorithm:
 performance  amount of comparison operations amount of data shifts (Datenverschiebungen) we neglect unimportant details and only count comparison and shifts of the data that we want to sort  data distribution  some of the algorithms differ in their efficiency in regards to how the data is sorted beforehand we distinguish between data that is already sorted (best case), data that is inversly sorted (worst case) and data that is unsorted (average case)  decomposability (Zerlegbarkeit)  is the sorting algorithm suitable for external sorting?</description>
    </item>
    
    <item>
      <title>Datastructures - Lecture 02</title>
      <link>https://schoettkr.github.io/knowledge-database/uni/ds/02_lecture/</link>
      <pubDate>Fri, 05 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>https://schoettkr.github.io/knowledge-database/uni/ds/02_lecture/</guid>
      <description>Continuing the repetition of some Algorithm lectures we went over pointers again.
int* pi; // pointer to int value (undefined) char** ppc; // pointer to char pointer (= pointer that points to a pointer pointing to a char :D) int i = 1; pi = &amp;amp;i; // assign address of i to pi int x = 1, y; int* px = &amp;amp;x; // pointer to x int** ppx = &amp;amp;px; // pointer to pointer of x **ppx = *px + 1; // double deferencing via &#39;**&#39;, equals x = x + 1 y = **ppx + 2; // double deferencing via &#39;**&#39;, equals y = x + 2  Now onto some new stuff!</description>
    </item>
    
    <item>
      <title>Datastructures - Lecture 01</title>
      <link>https://schoettkr.github.io/knowledge-database/uni/ds/01_lecture/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>https://schoettkr.github.io/knowledge-database/uni/ds/01_lecture/</guid>
      <description>In the first lectures of the datastructures we&amp;rsquo;ll repeat a few things that were already covered in the Algorithm &amp;amp; Programming Lecture so you may want to refer those blog posts as well. After all both courses belong to the same module.
Computational Effort &amp;amp; Complexity To compare datastructures and algorithms in regards to efficiency we need a way to measure the &amp;ldquo;cost&amp;rdquo; / computational effort. This is done by counting the required computing &amp;ldquo;steps&amp;rdquo; (Rechenschritte).</description>
    </item>
    
  </channel>
</rss>