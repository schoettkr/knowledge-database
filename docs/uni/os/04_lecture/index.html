<!doctype html>
<html>
  <head>
    <title>Operating Systems - Scheduling // schoettkr</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.59.1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Schoettkr" />
    <meta name="description" content="" />
    <base href="https://schoettkr.github.io/knowledge-database/" />
    <link rel="stylesheet" href="https://schoettkr.github.io/knowledge-database/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />
    <link rel="apple-touch-icon" sizes="180x180" href="./apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./favicon-16x16.png">
    <link rel="manifest" href="./site.webmanifest">
  </head>
  <body>
    <header class="app-header">
      <a href="/"><img class="app-header-avatar" src="./avatar.png" /></a>
      <h1>schoettkr</h1>
      <p>Software developer currently pursuing a master&#39;s degree in Germany</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/schoettkr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Operating Systems - Scheduling</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Apr 25, 2019
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          7 min read
        </div><div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
          <a class="tag" href="https://schoettkr.github.io/knowledge-database/tags/uni/">uni</a><a class="tag" href="https://schoettkr.github.io/knowledge-database/tags/os/">os</a></div></div>
    </header>
    <div class="post-content">
      

<h2 id="introduction">Introduction</h2>

<p>A &ldquo;process&rdquo; is a concept of virtualization of the hardware resource CPU. There&rsquo;s a <em>strategy</em> to decide which process is allowed to use the CPU at what time and there&rsquo;s a <em>mechanism</em> which refers to the way the strategy is carried out. <em>Dispatching</em> as the mechanism is what we covered in the last lecture. In this lecture we take a look at the strategy.<br />
Generally <em>scheduling</em> means the temporal assignment (zeitliche Zuordnung) of activities to ressources in regards. There different levels of granuality where scheduling occurs:</p>

<ul>
<li>when should programms start?</li>
<li>when should a process use a CPU?</li>
<li>when should a given instruction of an instruction sequence get executed?</li>
<li>when may a process use a device?</li>
<li>when may a program run in a cluster?</li>
</ul>

<p>In the sphere of operating systems however scheduling usually refers to the assignment of CPU resources. The scheduling strategy can have a significant impact on the performance of a system and choosing a strategy depends on certain goals (eg high efficiency, low latency, fairness, puncuality, high troughput).<br />
<img src="/knowledge-database/images/scheduling-schema.png" alt="" /><br />
<img src="/knowledge-database/images/execution-response.png" alt="" /></p>

<h2 id="common-scheduling-algorithms">Common Scheduling Algorithms</h2>

<p>The example(s) in the following slides assumes:</p>

<ul>
<li>a CPU with one core</li>
<li>ready list (Bereitliste) = queue of processes in &ldquo;ready&rdquo; state</li>
<li>the following five processes/tasks:</li>
</ul>

<figure>
    <img src="/knowledge-database/images/tasks.png"/> 
</figure>


<h3 id="first-come-first-serve">First Come First Serve</h3>

<ul>
<li>FCFS or FIFO (First In First Out)</li>
<li>tasks are processed in the order of their arrival in the ready list</li>
<li>tasks occupy CPU until they end or until voluntary release</li>
</ul>

<figure>
    <img src="/knowledge-database/images/fifo.png"/> 
</figure>


<h3 id="last-come-first-served-preemptive-resume">Last Come First Served - Preemptive Resume</h3>

<ul>
<li>LCFS-PR</li>
<li>new arrivals in the ready list suspend the current process</li>
<li>processes are processed as long as there are no new arrivals</li>
<li>the goal is to favor short processes

<ul>
<li>short processes have a higher chance to finish before another process arrives</li>
<li>long processes might be suspended multiple times</li>
</ul></li>
</ul>

<p><img src="/knowledge-database/images/lcfs-pr.png" alt="" />
<img src="/knowledge-database/images/lcfs-pr2.png" alt="" /></p>

<h3 id="round-robin--rr">Round Robin (RR)</h3>

<ul>
<li>processes are handled in order of arrival</li>
<li>after a specified period of time (&tau; time slice, quantum) suspension happens</li>
<li>the variant covered in this lecture puts new arriving &amp; suspended processes at the end of the queue and new processes have a higher priority</li>
<li>the goal of this strategy is an even distribution of the CPU capacity and of the waiting period for the processes</li>
<li>choosing the time slice &tau; is an optimization problem

<ul>
<li>in case of a large &tau; RR becomes more similar to FCFS</li>
<li>in case of a small &tau; the expense of frequent context switches rises</li>
</ul></li>
</ul>

<figure>
    <img src="/knowledge-database/images/round-robin.png"/> 
</figure>


<h3 id="priorities-nonpreemptive--prio-np">Priorities - Nonpreemptive (PRIO-NP)</h3>

<ul>
<li>new arrivals are sorted into the ready list in accordance to their priority and then processed until they end or voluntarily release</li>
</ul>

<figure>
    <img src="/knowledge-database/images/prio-np.png"/> 
</figure>


<h3 id="priorities-preemptive--prio-p">Priorities - Preemptive (PRIO-P)</h3>

<ul>
<li>like PRIO-NP however the current process is suspended if the priority is lower than the priority of a new arrival</li>
</ul>

<figure>
    <img src="/knowledge-database/images/prio-p.png"/> 
</figure>


<h3 id="shortest-job-next">Shortest Job Next</h3>

<ul>
<li>SJN or SPN (shortest process next)</li>
<li>process with the lowest execution time is executed until its end or voluntary release</li>
<li>same as PRIO-NP if PRIO-NP uses the execution time as priority criteria</li>
</ul>

<figure>
    <img src="/knowledge-database/images/sjn.png"/> 
</figure>


<h3 id="shortest-remaining-time-next">Shortest Remaining Time Next</h3>

<ul>
<li>SRTN</li>
<li>process with the shortest remaining time is processed next</li>
<li>current process can be suspended</li>
<li>favors shorter processes and leads on average to shorter response times than FCFS</li>
</ul>

<figure>
    <img src="/knowledge-database/images/srtn.png"/> 
</figure>


<p><strong>Note:</strong><br /></p>

<ul>
<li>SJN &amp; SRTN need to know the (remaining) execution time which can only come from the user in form of an estimation (disadvantage)</li>
<li>longer processes can &ldquo;starve&rdquo; when there are always shorter ones</li>
</ul>

<h3 id="highest-response-ratio-next">Highest Response Ratio Next</h3>

<ul>
<li>HRN</li>
<li>the response ratio \(r\) is defined as $r_r \frac{t_w + t_e}{t_e} where t_w is the waiting time and t_e is the execution time</li>
<li>process with the highest r_r value is chosen next</li>
<li>strategy is non-preemptive (nicht verdraengend)</li>
<li>as it is the case for SJN shorter processes are favored, however longer processes don&rsquo;t have to wait for ever but instead gain &ldquo;points&rdquo; by waiting (t_w increases)</li>
<li>again execution time has to be known</li>
</ul>

<figure>
    <img src="/knowledge-database/images/hrn.png"/> 
</figure>


<h3 id="multilevel-feedback">Multilevel Feedback</h3>

<ul>
<li>FB</li>
<li>scheduling algorithm with preempption per queue (Scheduling mit Verdraengung pro Warteschlange)</li>
<li>process goes into next queue after each time slice</li>
<li>queue \(i\) is processed when queue \(i-1\) is empty</li>
<li>different time slice durations &tau; are possible eg \(\tau = 2^i\)</li>
</ul>

<p><img src="/knowledge-database/images/fb1.png" alt="" />
<img src="/knowledge-database/images/fb2.png" alt="" /></p>

<h3 id="overview-of-common-scheduling-strategies">Overview of common Scheduling Strategies</h3>

<figure>
    <img src="/knowledge-database/images/scheduling-overview.png"/> 
</figure>


<p>Operating systems usually don&rsquo;t use just one, pure form of the scheduling algorithms, but instead mixed forms. Also keep in mind that scheduling involves an overhead (&rarr; cost-benefit analysis).</p>

<h3 id="classical-unix-scheduling">Classical UNIX Scheduling</h3>

<p>Scheduling in the UNIX-verse follows the principles of  multiple Feedback Queues in which Round Robin is used. The goal is to have a general fairness and favor interactive processes. Priorities (0..127) are assigned and put into queues (low value &rarr; high prio; high value &rarr; low prio). The priorities are computed based on the CPU usage by the process, the overall CPU load and user specifications.</p>

<figure>
    <img src="/knowledge-database/images/fq-unix.png"/> 
</figure>


<p>In the picture above four priorities are grouped into a queue, these are called <em>priority classes</em>. The priority gets reevalued at for example every forth timer tick. When a process gets a priority that belongs to another priority class, the process is sorted into the according queue. This is called <em>aging</em>. I/O-intensive processes are favored by this principle, because they occupy the CPU only for a short amount of time. This in turn leads to a high parallelism between the active computer components (CPU and periphery). Computing-intensive processes are penalized however. The priority computation might look similar to this:
\[P_J = min(P_{base} + [\frac{L_{CPU}}{4}] + 2 * p_{nice}, 127)\]</p>

<ul>
<li>P<sub>base</sub> is the base priority (eg 50)</li>

<li><p>p<sub>nice</sub> is an importance level that is user choosen in the range of eg -20..19</p>

<p>L<sub>CPU</sub> is value in the PCB of a running process and is incremented at each tick. Over time L<sub>CPU</sub> increases and therefore the priority values of longer running process would get really high (= low prio). That&rsquo;s why <em>smoothing</em> (Glaettung) exists. Smoothing cushions the impact of the last computation time and happens once per second:</p></li>
</ul>

<p>\[L&rsquo;_{CPU} = \frac{2*l_{RQ}}{2*l_{RQ} + 1} * L_{CPU} + p_{nice}\]</p>

<ul>
<li>l<sub>RQ</sub> is the average length of the ready queue in the last minute</li>
</ul>

<p>In the special case of blocking (sleeping) processes L&rsquo;<sub>CPU</sub> is computed differently because these processes&rsquo; L<sub>CPU</sub> values are not increased per timer ticks:
\[L&rsquo;_{CPU} = (\frac{2*l_{RQ}}{2*l_{RQ} + 1})^{t_{sleep}} * L_{CPU}\]</p>

<ul>
<li>t<sub>sleep</sub> is incremented once per second</li>
</ul>

<h3 id="linux-scheduling">Linux-Scheduling</h3>

<p>Note: This is a look at how scheduling was done in the old Linux 2.4.<br /></p>

<ul>
<li>process management via doubly linked lists

<ul>
<li>list to manage all processes</li>
<li>list to manage all processes that are ready to run</li>
</ul></li>
<li>the process classes

<ul>
<li>conventional processes (interactive or stack processed)

<ul>
<li>using prioritizing Round-Robin</li>
</ul></li>
<li>FIFO real time processes</li>
<li>RR real time processes</li>
</ul></li>
<li>the CPU time gets divided into epochs</li>
<li>in a single epoch, every process has a specified time quantum whose duration is computed when the epoch begins

<ul>
<li>at the end of a epoch all processes have used their time quantum</li>
</ul></li>
<li>each process has a <em>base time quantum</em> which is the time-quantum value assigned by the scheduler to the process if it has exhausted its quantum in the previous epoch

<ul>
<li>the users can change the base time quantum of their processes by using the <code>nice( )</code> and <code>setpriority( )</code> system calls</li>
<li>a new process always inherits the base time quantum of its parent</li>
</ul></li>
<li>the linux scheduler computes the goodness (Guete) of each runable process and chooses:

<ul>
<li>goodness = 0 &rarr; process has used its quantum</li>
<li>0 &lt; goodness &lt; 1000 &rarr; conventional process with a remaining quantum in this epoch</li>
<li>goodness &gt; 1000 &rarr; real time process</li>
</ul></li>
<li>see <a href="https://www.oreilly.com/library/view/understanding-the-linux/0596002130/ch11s02.html">https://www.oreilly.com/library/view/understanding-the-linux/0596002130/ch11s02.html</a></li>
<li><a href="https://www.linuxjournal.com/files/linuxjournal.com/linuxjournal/articles/039/3910/3910l3.html">here</a> is the source code of the goodness function</li>
<li>according to benchmark a core spends 37-55% in the goodness function (&rarr; bad scalability)</li>
</ul>

<p>The problem mentioned above lead to the development of the Linux \(\mathcal{O}(1)\) scheduler (from Linux 2.6 and upwards).
The goals in mind were to achieve an improved scalability and SMP (symmetric multi processing). There were new priority levels (140) introduced:</p>

<ul>
<li>0..99 for &ldquo;real time&rdquo;</li>
<li>100..139 for &ldquo;normal&rdquo; processes (in <code>top</code> etc displayed as 0..39)</li>
<li>user processes usually start with a priority of 119</li>
<li>priorities are assigned at start (<code>nice</code>) and vary by \(\pm 5\) max

<ul>
<li>CPU intensive tasks are punished</li>
<li>IO-intensive tasks are rewarded</li>
<li>interactive processes get their quantum &ldquo;refilled&rdquo; each milisecond</li>
</ul></li>
</ul>

<p>As in the previous scheduler each process has a time quantum:</p>

<ul>
<li><p>the quantum depends on the priority</p>

<pre><code class="language-C">#define BASE_TIMESLICE(p) (MIN_TIMESLICE + \
    ((MAX_TIMESLICE - MIN_TIMESLICE) * \
     (MAX_PRIO - 1 - (p)-&gt;static_prio / (MAX_USER_PRIO-1)))
</code></pre></li>

<li><p>per processor/core there are two priority arrays</p>

<ul>
<li>array for all processes with a positive quantum</li>
<li>array for all processes with a used up quantum</li>
</ul></li>

<li><p>each of these arrays consists of a bitmap and a queue of runable processes for every priority level</p>

<ul>
<li>bit in the bitmap specifies if a task is available in the corresponding queue</li>
</ul></li>

<li><p>when there are no more processes with a positive quantum then the pointer of the two arrays are swapped</p></li>

<li><p>the next process is chosen based on the first bit that is set in the bitmap (highest prio) which respond to each prio level; inside a prio level Round Robin is then used to manage the processes</p></li>
</ul>

<figure>
    <img src="/knowledge-database/images/prio-bitmap.png"/> 
</figure>


    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </body>
</html>
