<!doctype html>
<html>
  <head>
    <title>Operating Systems - Linear Memory Model // schoettkr</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.60.1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Schoettkr" />
    <meta name="description" content="" />
    <base href="https://schoettkr.github.io/knowledge-database/" />
    <link rel="stylesheet" href="https://schoettkr.github.io/knowledge-database/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />
    <link rel="apple-touch-icon" sizes="180x180" href="./apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./favicon-16x16.png">
    <link rel="manifest" href="./site.webmanifest">
  </head>
  <body>
    <header class="app-header">
      <a href="/"><img class="app-header-avatar" src="./avatar.png" /></a>
      <h1>schoettkr</h1>
      <p>Software developer currently pursuing a master&#39;s degree in Germany</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/schoettkr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Operating Systems - Linear Memory Model</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          May 1, 2019
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          6 min read
        </div><div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
          <a class="tag" href="https://schoettkr.github.io/knowledge-database/tags/uni/">uni</a><a class="tag" href="https://schoettkr.github.io/knowledge-database/tags/os/">os</a></div></div>
    </header>
    <div class="post-content">
      <h2 id="intro">Intro</h2>
<p>When a program is executed the instruction are present in memory/storage and then the CPU loads those instructions and executes them (program counter, Assembler). Hardware is able to deal with absolute (direct) and relative adressing modes.</p>
<ul>
<li>absolute (direct) addressing = memory locations of operands are specified as a whole and completely</li>
<li>relative addressing = memory locations are specified relative to the current PC (program counter) via on offset that is added to the address of the next instruction</li>
</ul>
<h2 id="address-space">Address Space</h2>
<p>Primary memory (RAM) is constituted via <strong>adress spaces</strong></p>
<ul>
<li>address space = a range of discrete memory addresses</li>
<li>logical address space = address(es) generated by a CPU and seen by programs</li>
<li>physical address space = address(es) that are seen by the memory unit and used to access memory units</li>
</ul>
<p>Virtual addresses are mapped with physical addresses by the MMU. In early computers logical and physical addresses corresponded, but since the introduction of virtual memory most application programs do not have a knowledge of physical addresses.</p>
<p>In this context the following challenges are faced:</p>
<ul>
<li>memory management <em>in</em> a linear address space (this chapter/post)</li>
<li>mapping logical to physical addresses (chapter 06;next post)</li>
<li>memory virtualization (chapter 07)</li>
</ul>
<h2 id="management-in-a--linear--address-space">Management in a (linear) Address Space</h2>
<p>From the application point of view (also OS intern) an address space is a <strong>linear</strong> list of addresses. However such linear address space is commonly not used as a whole but rather separated into memory areas (Speicherbereiche). The memory areas in an adress space are a limited resource and therefore require management. This is where the concepts of allocating and releasing memory come into place.<!-- raw HTML omitted -->
<img src="/knowledge-database/images/mm-concepts.png" alt=""></p>
<h3 id="concepts-of-memory-management">Concepts of Memory Management</h3>
<p>Usually memory gets allocated as multiples of fixed elementary sizes. So allocations are rounded up to the next multiple and this leads to memory locations that are marked as used but don't get used. For example, memory can only be provided to programs in chunks divisible by 4, 8 or 16, and as a result if a program requests perhaps 29 bytes, it will actually get a chunk of 32 bytes. When this happens, the excess memory goes to waste. In this scenario, the unusable memory is contained within an allocated region. This arrangement, termed fixed partitions, suffers from inefficient memory use - any process, no matter how small, occupies an entire partition. <strong>This waste is called internal fragmentation</strong>.<!-- raw HTML omitted -->
<strong>External fragmentation</strong> arises when free memory is separated into small blocks and is interspersed by allocated memory. It is a weakness of certain storage allocation algorithms, when they fail to order memory used by programs efficiently. The result is that, although free storage is available, it is effectively unusable because it is divided into pieces that are too small individually to satisfy the demands of the application. The term &ldquo;external&rdquo; refers to the fact that the unusable storage is outside the allocated regions.</p>
<h3 id="memory-occupation-information">Memory Occupation Information</h3>
<p>Information about memory (whether its free/used/occupied) is usually stored in a vector or a table. These informations are either stored <em>seperatedly</em> (requires additional memory) or <em>integrated</em> in the managed memory area.</p>
<h4 id="vector-representation">Vector Representation</h4>
<ul>
<li>a continous data structure that holds information about the complete memory space</li>
</ul>
<figure>
    <img src="/knowledge-database/images/memory-vector.png"/> 
</figure>

<h4 id="table-representation">Table Representation</h4>
<ul>
<li>information is stored about a specific state</li>
<li>slides: es werden nur Informationen ueber einen Zustand gespeichert (Belegungstabelle oder Freitabelle)</li>
</ul>
<p>Separated table representation (can be sorted by adress/length)<!-- raw HTML omitted -->
<img src="/knowledge-database/images/sep-table-rep.png" alt=""></p>
<p>Integrated table representation<!-- raw HTML omitted -->
<img src="/knowledge-database/images/int-table-rep.png" alt=""></p>
<ul>
<li>memory areas identify themselves</li>
<li>begin with length specification</li>
<li>include pointer to next element</li>
<li>sorting by length/adress is possible as well</li>
</ul>
<h4 id="selection-strategies">Selection Strategies</h4>
<p>When the process of reserving memory isn't determined automatically/by default then there needs to be some kind of strategy.</p>
<ul>
<li>First Fit</li>
</ul>
<pre><code><figure>
    <img src="/knowledge-database/images/first-fit.png"/> 
</figure>


-   the list (sorted by address) is run through from the beginning and the first chunk of memory that is big enough is selected
-   low search effort
-   segmentation of memory (external fragmentation)
-   concentration of used memory at the beginning (can lead to higher search effort down the line)
</code></pre>
<ul>
<li>Next Fit</li>
</ul>
<pre><code><figure>
    <img src="/knowledge-database/images/next-fit.png"/> 
</figure>


-   list is traversed in a cyclic manner
-   search starts where the last occupation happened
-   similar to first first but avoids the problem of concentration at the beginning of the memory chunk
</code></pre>
<ul>
<li>Best Fit</li>
</ul>
<pre><code><figure>
    <img src="/knowledge-database/images/best-fits.png"/> 
</figure>


-   the **smallest** sufficient chunk is chosen
-   when the list is sorted by address it has to be completely traversed, that's why sorting by size should be favored in this case
-   improved memory utilization because smaller allocation requests are fulfilled by using small chunks instead of sratching of larger chunks
-   however this tends to create very small chunks which then might not be used at all (external fragmentation)
</code></pre>
<ul>
<li>Nearest Fit</li>
</ul>
<pre><code><figure>
    <img src="/knowledge-database/images/nearest-fit.png"/> 
</figure>


-   a desired adress is passed for the requested chunk
-   the algorithm then begins a first-fit search starting at the requested address
</code></pre>
<h4 id="premanufactured-memory--vorkonfektionieren">Premanufactured Memory (Vorkonfektionieren)</h4>
<p>The search effort for arbitrary releases and allocations is \(\mathcal(O)(n)\). This effort can be reduced by &ldquo;premanufactured&rdquo; (vorkonfektionierte) chunks, meaning that the statistically most-requested sizes should be kept ready (Konfektionsware) which can then be accessed via a sorted binary tree.<!-- raw HTML omitted -->
<img src="/knowledge-database/images/konfekt-memory1.png" alt="">
<img src="/knowledge-database/images/konfekt-memory2.png" alt=""></p>
<h4 id="memory-release">Memory Release</h4>
<p><img src="/knowledge-database/images/memory-release.png" alt=""><!-- raw HTML omitted -->
The memory release can be optimized:
<img src="/knowledge-database/images/memory-release2.png" alt=""><!-- raw HTML omitted --></p>
<h3 id="examples-of-concrete-methods">Examples of Concrete Methods</h3>
<h4 id="ring-buffer-queue-method">Ring Buffer / Queue Method</h4>
<ul>
<li>allocation and releasing in same order (FIFO)</li>
<li>chunks are of equal size</li>
<li>no searching</li>
<li>no external fragmentation, but internal fragmentation is possible</li>
<li>automatic, instant reintegration</li>
<li>real world example: eg buffer for device drivers (Uebergabepuffer bei Geraetetreibern)</li>
</ul>
<figure>
    <img src="/knowledge-database/images/ringbuffer.png"/> 
</figure>

<h4 id="stack-method">Stack Method</h4>
<figure>
    <img src="/knowledge-database/images/stack.png"/> 
</figure>

<ul>
<li>allocating and releasing happens in reverse order (LIFO)</li>
<li>chunks of arbitrary sizes</li>
<li>no searching</li>
<li>automatic, instant reintegration</li>
<li>real world example: eg local variables of a program</li>
</ul>
<h4 id="vector-method">Vector Method</h4>
<figure>
    <img src="/knowledge-database/images/vector.png"/> 
</figure>

<ul>
<li>allocating and releasing in arbitrary order</li>
<li>chunk size = $k * $  Grundeinheit</li>
<li>search for the first fitting chunk</li>
<li>internal and external fragmentation</li>
<li>automatic, instant reintegration</li>
<li>real world example: eg kernel storage for very small systems</li>
</ul>
<h4 id="boundary-tag-method">Boundary Tag Method</h4>
<figure>
    <img src="/knowledge-database/images/boundary-tag.png"/> 
</figure>

<ul>
<li>chunks are tagged</li>
<li>chunks are chained by size</li>
<li>allows allocation of arbitrary sizes</li>
<li>occupation data and chunk managment is integrated (doubly linked list)</li>
<li>external fragmentation</li>
<li>explicitly initiated, instant reintegration
<ul>
<li>makes use of the length arrays to check the neighbours</li>
<li>sorted insertion into the linked list</li>
</ul>
</li>
<li>real world example: eg <code>malloc</code> in the GNU C library builds on a boundary tag method (but much more complex)</li>
</ul>
<h4 id="buddy-system">Buddy System</h4>
<ul>
<li>memory consists of \(2^{k_{max}}\) units</li>
<li>smaller chunks are a result of continous halving/bisection of larger chunks</li>
<li>smaller chunks that were produced together are merged back into larger chunks when released</li>
<li>allocating and releasing in arbitrary order</li>
<li>allocation in chunk sizes of \(2^0, 2^1, 2^2, &hellip;, 2^k\)</li>
<li>not much searching</li>
<li>internal and external fragmentation</li>
<li>release explicitly carried out</li>
</ul>
<p>Sequence of Allocation</p>
<ul>
<li>round up to next power of two</li>
<li>access of first available chunk in the list</li>
<li>if list is empty (recursive):
<ul>
<li>access list of next bigger size</li>
<li>remove a chunk</li>
<li>half that chunk</li>
<li>insert the latter half (back?) into the list</li>
</ul>
</li>
</ul>
<p>Sequence of Release</p>
<ul>
<li>determine buddy (the other half)</li>
<li>if buddy is occupied → insert the released chunk into its list</li>
<li>if buddy is free → merge buddies</li>
<li>repeat this process until there's an occupied buddy or arrived at largest size</li>
<li>fast operations</li>
<li>adapts to requirements profile</li>
<li>relatively high internal fragmentation</li>
<li>after initial phase there're usually little division and merging processes</li>
<li>real world example: eg <code>jemalloc()</code> (FreeBSD)</li>
</ul>
<figure>
    <img src="/knowledge-database/images/buddy-system.png"/> 
</figure>

<hr>
<p>Good and concise overview <a href="https://medium.com/cracking-the-data-science-interview/how-operating-systems-work-10-concepts-you-should-know-as-a-developer-8d63bb38331f">https://medium.com/cracking-the-data-science-interview/how-operating-systems-work-10-concepts-you-should-know-as-a-developer-8d63bb38331f</a></p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
    
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </body>
</html>
