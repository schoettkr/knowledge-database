<!DOCTYPE html>
<html prefix="" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Algos &amp; Programming - Lecture 15 &amp; 16 | Knowledge Database</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.xml">
<link rel="canonical" href="https://schoettkr.github.io/knowledge-database/posts/algos_and_programming/algos-and-prog-15-16/">
<!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><meta name="author" content="schoettkr">
<meta property="og:site_name" content="Knowledge Database">
<meta property="og:title" content="Algos &amp; Programming - Lecture 15 &amp; 16">
<meta property="og:url" content="https://schoettkr.github.io/knowledge-database/posts/algos_and_programming/algos-and-prog-15-16/">
<meta property="og:description" content="This blog post contains the material covered in lecture 15 and 16 because it is the same subject and it does not make sense to split it :P.



Complexity


As you've hopefully already noticed there ar">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2018-11-26T00:00:00+01:00">
<meta property="article:tag" content="A&amp;P">
<meta property="article:tag" content="university">
</head>
<body>
    

    <header id="header" class="navbar"><div class="container">
            
    <div class="brand">

        <div class="brand-text">
            <a href="https://schoettkr.github.io/knowledge-database/" title="Knowledge Database" rel="home">
                Knowledge Database
            </a>
        </div>

        <a id="btn-toggle-nav" class="navbar-toggle">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </a>
    </div>

            
    <nav class="navbar-collapse collapse"><ul class="nav">
<li><a href="../../../archive.html">Archive</a></li>
                <li><a href="../../../categories/">Tags</a></li>
                <li><a href="../../../rss.xml">RSS feed</a></li>
    
    
    </ul></nav>
</div>
    </header><div class="header-padding"> </div>

    
    <div class="post-header">
        <div class="container">
            <div class="title">
                Algos &amp; Programming - Lecture 15 &amp; 16
            </div>
        </div>
    </div>

    <div class="post-meta">
      <div class="container">
	<div class="meta clearfix">
	  <div class="authordate">
	    <time class="timeago" datetime="2018-11-26T00:00:00+01:00">2018/11/26</time>
	    

	    
          |  
        <a href="index.org" id="sourcelink">Source</a>

	  </div>
	  <div class="post-tags">
	    <div class="tag">
	      <a href="../../../categories/ap/" rel="tag">A&amp;P</a>
	    </div>
	    <div class="tag">
	      <a href="../../../categories/university/" rel="tag">university</a>
	    </div>
	  </div>
	</div>
      </div>
    </div>


    <div id="post-main" class="main">
        <div class="container">
        <p>
This blog post contains the material covered in lecture 15 and 16 because it is the same subject and it does not make sense to split it :P.
</p>

<div id="outline-container-orgd96ab9c" class="outline-2">
<h2 id="orgd96ab9c">Complexity</h2>
<div class="outline-text-2" id="text-orgd96ab9c">
<p>
As you've hopefully already noticed there are algorithms that differ in regards to <i>efficiency</i>. <b>Algorithmic efficiency</b> refers to the number of <b>computational resources</b> (<i>computation time</i> and <i>memory space</i>) used by the algorithm.
</p>

<p>
For maximum efficiency we wish to minimize resource usage. However, different resources such as time and space complexity cannot be compared directly, so which of two algorithms is considered to be more efficient often depends on which measure of efficiency is considered most important.
</p>
</div>

<div id="outline-container-orgfe55b46" class="outline-3">
<h3 id="orgfe55b46">RAM Model</h3>
<div class="outline-text-3" id="text-orgfe55b46">
<p>
It is impractical to measure the computation time with a stopwatch or operating system functions because then there'd be a lot of other factors involved such as compiler, hardware and operating system.
</p>

<p>
But to measure the quality of <i>algorithms</i> (not their implementation) we don't even need a time because we use <i>abstract computer models</i>. For example the <b>Random Access Machine</b> (RAM model) which is used for computational complexity analysis.
</p>

<p>
RAM Components:
</p>
<ul class="org-ul">
<li>
<b>program</b>
<ul class="org-ul">
<li>numbered, finite series of instructions</li>
</ul>
</li>
<li>
<b>storage</b>
<ul class="org-ul">
<li>enumerable (infinite) amount of storage locations(registers) (slides: abzählbar (unendlich) viele Speicherstellen (Register))</li>
<li>arbitrarily accessible</li>
<li>every register can store an arbitrary integer</li>
</ul>
</li>
<li>
<b>in-/output</b>
<ul class="org-ul">
<li>continuous sequences (bänder, ribbons)</li>
<li>either input (read) or output (write) in the given situation</li>
</ul>
</li>
<li>central processing unit
<ul class="org-ul">
<li>instruction counter that holds the number of the instruction that is to be executed</li>
<li>accumulator = target register of computations, address 0</li>
<li>arithmetic logic unit = enginge / functional unit for execution of operations</li>
</ul>
</li>
</ul>
<p>
<img src="../../../images/random-access-machine.png" alt="nil"></p>

<p>
The "common/usual" instructions are available in a RAM:
</p>
<ul class="org-ul">
<li>basic arithmetic operations: + - * / mod</li>
<li>comparisons: &gt; &lt; = ≥ ≤</li>
<li>branching/conditions: if</li>
<li>jumps : GOTO (loops are branches with jumps btw)</li>
<li>loading/storing: LOAD, STORE</li>
<li>in-/output: READ, WRITE</li>
</ul>
<p>
Operands:
</p>
<ul class="org-ul">
<li>registers (can be chosen arbitrarily), also indirectly</li>
<li>accumulator (implicit)</li>
<li>input sequence and output sequence (not arbitrarily ~ nicht wahlfrei)</li>
</ul>
<p>
For the RAM there are two models of measuring the time cost:
</p>
<ul class="org-ul">
<li>uniform cost measure: every instruction has a time cost of 1 time unit (eg Takt/clock signal or millisecond ..)
<ul class="org-ul">
<li>since every instruction has the same length/duration the instrucion <b>executions</b> are determining the cost</li>
</ul>
</li>
<li>logarithmic time cost measure: the length of the numbers that have to be processed determine the time
<ul class="org-ul">
<li>length l(x) of x ∈ G:  l(0) = 1, l(x) = (log<sub>2</sub> |x|) + 1</li>
<li>the logarithmic time costs of an instruction are equal to the sum of the length of the numbers that have to be processed</li>
<li>the logarithmic time cost measure should be usend when the size/length of the numbers is of critical significance</li>
<li>in addition to the instruction executions the size of the operands is of importance in regards to the cost</li>
</ul>
</li>
</ul>
<p>
Instructions that are executed in a loop are counted repeatedly and since the execution of instructions (and loop iterations) often depends on the input size n we measure the amount of instructions that are executed with T<sub>A</sub>(n), for example:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-left">
</colgroup>
<thead><tr>
<th scope="col" class="org-left">Algorithm</th>
<th scope="col" class="org-left">T<sub>A</sub>(n)</th>
<th scope="col" class="org-left">optimal for</th>
</tr></thead>
<tbody>
<tr>
<td class="org-left">A<sub>1</sub>
</td>
<td class="org-left">1000 * n</td>
<td class="org-left">n ≥ 101</td>
</tr>
<tr>
<td class="org-left">A<sub>2</sub>
</td>
<td class="org-left">200*n*log n</td>
<td class="org-left">never</td>
</tr>
<tr>
<td class="org-left">A<sub>3</sub>
</td>
<td class="org-left">10 * n<sup>2</sup>
</td>
<td class="org-left">10 ≤ n ≤ 100</td>
</tr>
<tr>
<td class="org-left">A<sub>4</sub>
</td>
<td class="org-left">2<sup>n</sup>
</td>
<td class="org-left">1 ≤ n ≤ 9</td>
</tr>
</tbody>
</table>
</div>

<ul class="org-ul">
<li>
<a id="orgea74082"></a>Run-time Analysis<br><div class="outline-text-5" id="text-orgea74082">
<p>
Even for constant \(n\) is T<sub>A</sub> not always the same:
</p>
<ul class="org-ul">
<li>worst case analysis
<ul class="org-ul">
<li>for every n define the runtime as T(n) = max(t(Input)), ∀ |Input| = n</li>
<li>guaranteed boundaries for every input</li>
<li>used as standard</li>
</ul>
</li>
<li>average case analysis
<ul class="org-ul">
<li>for every n define the runtime as T(n) = \(\bar{t}\)(Input) ∀ |Input| = n</li>
<li>depends on the definition of average → distribution of inputs</li>
<li>rarely used (hard to determine the average)</li>
</ul>
</li>
<li>best case analysis
<ul class="org-ul">
<li>for every n define the runtime as T(n) = min(t(Input)), ∀ |Input| = n</li>
<li>looks for minimal runtime</li>
<li>shows design mistakes (Entwurfsfehler)</li>
<li>has no real significance (easy to cheat)</li>
</ul>
</li>
</ul>
<p>
In general the analysis of T<sub>A</sub> is rather hard that's why <i>order of magnitudes</i> (Größenordnungen) are used more commonly. We know such from real life eg: v<sub>Laufen</sub> &lt; v<sub>Rad</sub> &lt; v<sub>Auto</sub> &lt; v<sub>Flugzeug</sub></p>

<p>
Note: I skipped the slides on "big A notation" here because I fail to see the relevance of it and cant find anything about in the internet (slides 14-15, chapter 8).
</p>
</div>
</li>
</ul>
</div>
</div>
<div id="outline-container-orge232fb0" class="outline-2">
<h2 id="orge232fb0">Big O Notation</h2>
<div class="outline-text-2" id="text-orge232fb0">
<p>
Often times the <b>growth rate</b> of algorithms/function is of interest. The <b>big-O notation</b> is commonly used to describe how a function grows. A common goal is to find algorithms/functions that are still efficient for large problem instances (inputs) and if that is the case we usually say that they scale good. Two functions eg \(f(n)\) and \(g(n)\) have the same growth rate when the ratio for a sufficient amount of \(n\) is limited by the same constant upper and lower boundaries (slides: Zwei Funktionen f(n) und g(n) haben das gleiche Wachstumsverhalten, falls für genügend große n das Verhältnis der beiden nach oben und unten durch Konstanten beschränkt ist), which means that \(c &lt; \frac{f(n)}{g(n)} and \frac{g(n)}{f(n)}\) needs to be true.
For example:
</p>
<ul class="org-ul">
<li>\(f_1(n)=n^2\) and \(f_2(n)=5*n^2-7*n\) have the <b>same grow</b> because for all \(n &gt; 2\) the following applies: \(\frac{1}{5} &lt; \frac{(5n^2-7n)}{n^2} &lt; 5\) and \(\frac{1}{5} &lt; \frac{n^2}{(5n^2-7n)} &lt; 5\)</li>
<li>\(f_1(n)=n^2\) and \(f_2(n)=n^3\) do <b>not have the same grow</b> because for all sufficient large \(n\) (hinreichend groß) the following applies \(\frac{n^3}{n^2} = n &gt; c\)</li>
</ul>
<p>
The big O notation (big O refers to the greek letter omikron) is also called <b>Landau Notation</b>.
</p>

<p>
Big O Notation can also be used to state which function dominates the growth. For two monotone function f(n) and g(n) the function f(n) dominates the function g(n) if \(g(n) \in \mathcal{O}(f(n))\). The notation \(dom(f(n),g(n))\) yields the dominating function. For example
</p>
<ul class="org-ul">
<li>dom(n<sup>3</sup>, n<sup>2</sup>) = n<sup>3</sup>
</li>
<li>dom(2<sup>n</sup>, n<sup>k</sup>) = 2<sup>n</sup> (for constant k &gt; 1)</li>
</ul>
<p>
There are also some computation rules (Rechenregeln) when it comes to big O:
\[
\mathcal{O}(f(n)) + \mathcal{O}(g(n)) = \mathcal{O}(f(n) + g(n))\\
\mathcal{O}(f(n) + g(n)) = \mathcal{O}(dom(f(n), g(n)))\\
\mathcal{O}(f(n)) * \mathcal{O}(g(n)) = \mathcal{O}(f(n) * g(n))
\]
</p>

<p>
These are some common types/classes of functions in regards to big O:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-left">
</colgroup>
<thead><tr>
<th scope="col" class="org-left">Notation</th>
<th scope="col" class="org-left">Term</th>
<th scope="col" class="org-left">Typical Algorithms/Operations</th>
</tr></thead>
<tbody>
<tr>
<td class="org-left">O(1)</td>
<td class="org-left">constant</td>
<td class="org-left">addition, comparisons, recursive call</td>
</tr>
<tr>
<td class="org-left">O(log n)</td>
<td class="org-left">logarithmic</td>
<td class="org-left">search in a sorted sequence</td>
</tr>
<tr>
<td class="org-left">O(n)</td>
<td class="org-left">linear</td>
<td class="org-left">modifying each element of a set</td>
</tr>
<tr>
<td class="org-left">O(n * log n)</td>
<td class="org-left"> </td>
<td class="org-left">good sorting algorithm</td>
</tr>
<tr>
<td class="org-left">O(n * log n)</td>
<td class="org-left"> </td>
<td class="org-left">good sorting algorithms</td>
</tr>
<tr>
<td class="org-left">O(n * log<sup>2</sup> n)</td>
<td class="org-left"> </td>
<td class="org-left">good sorting algorithms</td>
</tr>
<tr>
<td class="org-left">…</td>
<td class="org-left">….</td>
<td class="org-left">…</td>
</tr>
<tr>
<td class="org-left">O(n<sup>2</sup>)</td>
<td class="org-left">quadratic</td>
<td class="org-left">primitive sorting algorithms</td>
</tr>
<tr>
<td class="org-left">O(n<sup>k</sup>), k &gt;= 2</td>
<td class="org-left">polynomial</td>
<td class="org-left">primitive sorting algorithms</td>
</tr>
<tr>
<td class="org-left">…</td>
<td class="org-left">…</td>
<td class="org-left">…</td>
</tr>
<tr>
<td class="org-left">O(2<sup>n</sup>)</td>
<td class="org-left"> </td>
<td class="org-left">trying combinations</td>
</tr>
<tr>
<td class="org-left">O(k<sup>n</sup>), k &gt; 1</td>
<td class="org-left">exponential</td>
<td class="org-left"> </td>
</tr>
</tbody>
</table>
<p>
The O(n)-notation depends on the size of the input, that is the storage space in bits or words. 
</p>

<p>
In addition to the most common big O notation there are several related notations to describe other kinds of bounds on asymptotic growth rates:
</p>
<ul class="org-ul">
<li>big Omega notation \(\Omega(f(n)) = {g(n) \exists c &gt; 0, \exists n_0 &gt;0, \forall n &gt; n_0, g(n) \geq c * f(n)}\) → lower boundary / "mindestens"</li>
<li>big Theta notation \(\Theta(f(n)) = \mathcal{O}(f(n)) \cap \Omega(f(n))\) → exactly / "genau"</li>
<li>little o notation \(o(f(n)) = {g(n) | \forall c &gt; 0, \exists n_0 &gt; 0, \forall n &gt; n_0, g(n) \leq c*f(n)}\) → at max / "weniger"</li>
<li>little omega notation \(o(f(n)) = {g(n) | \forall c &gt; 0, \exists n_0 &gt; 0, \forall n &gt; n_0, g(n) \geq c*f(n)}\) →  "mehr"</li>
</ul>
<p>
What followed in the slides are some example computation times for different complexities and algorithms.
</p>

<p>
Take for example the algorithm to search the minimum in a sequence:
</p>
<div class="highlight"><pre><span></span><span class="nl">require</span><span class="p">:</span> <span class="n">sequence</span> <span class="n">a_1</span><span class="p">,</span> <span class="p">...,</span> <span class="n">a_n</span><span class="p">;</span>
<span class="nl">ensure</span><span class="p">:</span> <span class="n">p</span> <span class="o">=</span> <span class="n">min</span><span class="p">(</span><span class="n">a_1</span><span class="p">,...,</span> <span class="n">a_n</span><span class="p">);</span>

<span class="n">p</span> <span class="o">&lt;-</span> <span class="n">a_1</span>

<span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="p">...,</span> <span class="n">n</span><span class="p">}</span> <span class="k">do</span>
  <span class="k">if</span> <span class="n">a_i</span> <span class="o">&lt;</span> <span class="n">p</span> <span class="n">then</span>
    <span class="n">p</span> <span class="o">&lt;-</span> <span class="n">a_i</span>
  <span class="n">end</span> <span class="k">if</span>
<span class="n">end</span> <span class="k">for</span>
</pre></div>

<p>
In the above example the complexities are \(\mathcal{O}(n)\), Ω (n) and Θ (n).
</p>

<p>
Take a look at the lecture slides (chapter 8) from slide 26 to see some more examples.
</p>
</div>

<div id="outline-container-org1c4b604" class="outline-4">
<h4 id="org1c4b604">Better Sorting</h4>
<div class="outline-text-4" id="text-org1c4b604">
<p>
The sorting algorithms we saw so far (bubble sort and insertion sort) have a complexity in \(\mathcal{O}(n^2)\). Quicksort and Mergesort are generally better sorting algorithms. Let's look at quicksort:
</p>
<div class="highlight"><pre><span></span><span class="nl">require</span><span class="p">:</span> <span class="n">array</span> <span class="o">=</span> <span class="p">{</span><span class="n">e_1</span><span class="p">,</span> <span class="n">e_2</span><span class="p">,</span> <span class="p">...,</span> <span class="n">e_n</span><span class="p">};</span>
<span class="nl">ensure</span><span class="p">:</span> <span class="k">for</span> <span class="n">all</span> <span class="n">i</span> <span class="n">in</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span> <span class="n">e_i</span> <span class="o">&lt;=</span> <span class="n">e_</span><span class="p">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">}</span> <span class="c1">// sorted sequence condition </span>

<span class="n">procedure</span> <span class="n">QSORT</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
  <span class="k">if</span> <span class="o">|</span><span class="n">array</span><span class="o">|</span> <span class="o">&lt;=</span> <span class="n">then</span> 
    <span class="k">return</span> <span class="n">array</span>
  <span class="n">end</span> <span class="k">if</span>

  <span class="n">select</span> <span class="n">and</span> <span class="n">remove</span> <span class="n">a</span> <span class="n">pivot</span> <span class="n">value</span> <span class="s">"pivot"</span> <span class="n">from</span> <span class="n">array</span>

  <span class="n">less</span> <span class="o">&lt;-</span> <span class="p">[]</span>
  <span class="n">greater</span> <span class="o">&lt;-</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">e</span> <span class="n">in</span> <span class="n">array</span> <span class="k">do</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">&lt;=</span> <span class="s">"pivot"</span> <span class="n">then</span>
      <span class="n">append</span> <span class="n">e</span> <span class="n">to</span> <span class="n">less</span>
    <span class="k">else</span> 
      <span class="n">append</span> <span class="n">e</span> <span class="n">to</span> <span class="n">greater</span>
    <span class="n">end</span> <span class="k">if</span>
  <span class="n">end</span> <span class="k">for</span>

  <span class="k">return</span> <span class="n">concatenate</span><span class="p">(</span><span class="n">QSORT</span><span class="p">(</span><span class="n">less</span><span class="p">),</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">QSORT</span><span class="p">(</span><span class="n">greater</span><span class="p">))</span>
<span class="n">end</span> <span class="n">procedure</span>
</pre></div>

<p>
Because of the built-in list type a quicksort implementation in Python is pretty easy:
</p>
<div class="highlight"><pre><span></span><span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">54</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">qsort</span><span class="p">(</span><span class="nb">list</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">list</span> <span class="o">==</span> <span class="p">[]:</span>
	<span class="k">return</span> <span class="p">[]</span>
    <span class="k">else</span><span class="p">:</span>
	<span class="n">pivot</span> <span class="o">=</span> <span class="nb">list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
	<span class="n">less</span> <span class="o">=</span> <span class="p">[]</span>
	<span class="n">greater</span> <span class="o">=</span> <span class="p">[]</span>
	<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">list</span> <span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
	    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">pivot</span> <span class="p">:</span> <span class="n">less</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	    <span class="k">else</span> <span class="p">:</span> <span class="n">greater</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">qsort</span><span class="p">(</span><span class="n">less</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">pivot</span><span class="p">]</span> <span class="o">+</span> <span class="n">qsort</span><span class="p">(</span><span class="n">greater</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">qsort</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>
</pre></div>

<pre class="example">
[2, 7, 8, 9, 54]

</pre>

<p>
The depth of the recursion in quick sort is not set in stone. How does the worse case look? The pivot element is always the smallest or largest element in the list so the recursion depth is n - 1 (why?). On each recursion call \(i = |array| - 1\) elements are handled  which results in a recursion depth of n - recursion depth. 
In the worst case the complexity would be Θ(n<sup>2</sup>) so it wouldn't <b>always</b> be better than eg bubble sort! In such situation it makes sense to look at the average case (see slide 35 for that).
</p>
</div>
</div>

<div id="outline-container-orgde57488" class="outline-4">
<h4 id="orgde57488">Space Complexity (Storage/Memory)</h4>
<div class="outline-text-4" id="text-orgde57488">
<p>
The required memory space is another critical resource in addition to the computation time. To measure this the same complexity measures are used. Let's look at the required storage space complexity for quicksort:
</p>
<ul class="org-ul">
<li>new arrays are created on each recursion</li>
<li>the required storage space is \(n\) in every recursion depth</li>
<li>the maximum recursion depth is \(n-1\)</li>
</ul>
<p>
→ storage complexity of quicksort is \(\mathcal{O}(n^2)\).
</p>

<p>
However a storage complexity of \(\mathcal{O}(n)\) is achievable via a smart quicksort implementation by using <i>in place</i> mutations. 
</p>
</div>
</div>
</div>
        
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
        </script>
</div>
    </div>

    
    <footer><div class="container">
            <div class="social">



                <div class="social-entry">
                    <a href="../../../rss.xml" target="_blank">
                        <i class="fa fa-rss"></i> 
                    </a>
                </div>
            </div>
                <div class="copyright">
                    Contents © 2018         <a href="mailto:schoettkr@gmail.com">schoettkr</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
                    
                </div>
           
        </div>
    </footer><script src="../../../assets/js/all-nocdn.js" type="text/javascript"></script>
</body>
</html>
