#+TITLE: Operating Systems - Address Mapping
#+DATE: 2019-05-08 10:00
#+HUGO_TAGS: uni os
#+HUGO_BASE_DIR: ../../../
#+HUGO_SECTION: uni/os
#+HUGO_DRAFT: false
#+HUGO_AUTO_SET_LASTMOD: true

* Intro
Primary memory (RAM) is constituted via *adress spaces*
- address space = a range of discrete memory addresses
- logical address space = address(es) generated by a CPU and seen by programs
- physical address space = address(es) that are seen by the memory unit and used to access memory units

The physical and the logical/virtual address space (and virtual address spaces between each other) may differ in regards to their size and structure. The point of view of a running program (that is the logical pov) gets already incorporated during /compilation time/.

The logical address space is divided into different functional parts:
- *code* = machine code of the running program 
- *initialized/uninitialized variables* = global or static variables, literals (eg constant char strings) etc
- *heap* = global data, which is not part of a function (global variables)
- *stack* = local data of functions (return addresses, local variables, parameter)
- program & data are shared in case of multiple processes per address space (threads), but the stacks are specific to each thread

[[/knowledge-database/images/logical-address-space.png]]

But what about the address space of the kernel? There are 2 approaches:
- kernel "lives" in the address space of every process (usually the case nowadays)
  - from the OS pov logical addresses always stay the same
  - cache data of the OS are preserved
  - requires expicit guarding of the OS data
- kernel has its own address space
  - larger address space when for the use case of virtualization
  - performance loss because of cache invalidation etc
    
For example in Linux one may choose the kernel configuration:
- the 3G/1G configuration corresponds to Variant 1
- the 4G/4G configuration corresponds to Variant 2

\rightarrow 4G/4G results in 30% less performance in comparison to 3G/1G

The physical address space corresponds to the hardware POV. Besides the RAM, the ROM and address space of I/O-devices may belong to the physical address space.\\
[[/knowledge-database/images/physical-address-space.png]]

* Memory Mapping
How are logical address spaces mapped to the physical address space? We'll look at different variants.
** Direct Mapping (Compile Time Binding)
- in an executable (i.e after compiling & linking) physical addresses are directly used (address in the program = physical memory address)
- logical address space are subregions (Teilbereiche) of the physical address space
- addresses are chosen/determined by the compiler/linker
  - address binding at translation time
- location of the program in main memory is set/fixed and cannot be changed
[[/knowledge-database/images/direct-mapping-1.png]]

A problem of this approach is that the address binding at translation time leads to problems in multitasking systems (Mehrprogrammbetrieb).
[[/knowledge-database/images/direct-mapping-2.png]]
So programs could only be loaded into memory when the address spaces are completely different and do not overlap. Assigning addresses at translation time happens without knowledge of occupation states i.e too early and this would not allow efficient dynamic memory usage.\\
So this approach is only usable when all programs (and the OS) are translated together which might for example be the common case for \mu controllers in embedded systems.

** Load Time Binding
- idea: final addresses are determined when the program is /loaded/
  
Variant 1: *position-independent code (PIC)*
- assembler code only uses *relative* addressing
- has to be supported by the compiler (eg the option =-fPIC= for gcc/clang)
- usually the reachable/accessible /relative/ address space is smaller than the /absolute/ address space
  - size of data is limited
  - Realisierung weiter Spruenge durch "Kettenspruenge"
- body of machine code that, being placed somewhere in primary memory, executes properly regardless of its absolute address
- PIC is commonly used for shared libraries so that the same library code can be loaded in a location in each program adress space where it will not overlap any other uses of memory (https://de.wikipedia.org/wiki/Position-independent_Code)

Variant 2: *relocatable code*
- programs are in a relocatable format (eg MZ or ELF)
- at load-time logical addresses are converted to physical addresses
- the loader does this

[[/knowledge-database/images/relocatable-code.png]]

** Relocation with Base Register
- when binding at load time (prev approach) all addresses are set after loading
- a more flexible approach is *address binding at runtime*
  - requires hardware support
  - processor has (on or more) *base adress register* which gets set to the appropriate starting address when a program is loaded
  - logical address spaces begin evermore (stets) at address 0
- base address register is added to the program address at each memory access
- slides: Nun können u.a. Speicherverdichtungen durchgeführt werden, ohne Code oder Daten zu ändern

[[/knowledge-database/images/base-register.png]]

Note: Don't confuse this with the /relative addressing mode/ and direct mapping with the /direct addressing mode/ (see prev post). Sometimes these terms are used in the literature for this but we avoid them to avoid mixing them.

** Strewing Mapping (Streuende Abbildung)
- idea: separation of logical address space in smaller subregions/chunks which are independantly of each other mapped to the physical address space
- those chunks can have the same size (paging) or be of different size (segmentation)
- memory management informations themselves lay in memory
- mapping is configured by the OS (strategy)
- address translation on the fly by the Memory Management Unit (MMU)
*** Paging
- splitting memory (or addresses) into equally large chunks/subregions
- no external but internal segmentation
- the subregions of the logical address space are called *pages*
- the physical address space gets divided into *page frames*

[[/knowledge-database/images/paging.png]]

Logical addresses then consist of two parts. The /page number/ and the offset/displacement (relative address) in that page. The CPU merely needs the physical base address of the page table. The MMU then determines the physical page via the logical page number and the according page table entry. The offset is then added to the physical page number which together amounts to the physical address.

- the MMU basically just "sorts" pages in accordance to the paging table
- via the page table identical logical addresses lead to the same physical addresses (would lead to similar problems as direct mapping)
- there are two approaches to solve this problem:
  - every process gets its own page table
    - the logical address space of all processes can be the same
    - only the register with the table base address has to be changed when switching processes
    - usually requires more primary storage/memory
  - processes have a different (disjunct) logical addressraum
    - requires only one page table
    - address space have to be made disjunct at load time via /relocatable code/ 
    - in contrast to code-relocation no external segmentation occurs
      
The /page size/ is set by the hardware but can usually be configured through the system. What size should a page have?

*small pages*
- PRO: less segmentation
- CON: longer/larger page tables

*large pages*
- PRO: shorter/smaller page tables
- CON: more segmenation

Estimation of segmentation (storage waste):
- $a =$ length of the logical address space
- $p =$ page length
  
Average segmenation $= \frac{p}{2}$\\
Length of page table when one word is used per entry $= \frac{a}{p}
Relative total storage waste: $d = \frac{\frac{a}{p} \frac{p}{2}}{a} = \frac{1}{p} + \frac{p}{2a}$\\
Optimizable via $p_{opt}=\sqrt{2*a}

*Multilevel Page Table* (Mehrstufige Seitentabelle)\\
- problem: page tables can get large and there can be a lot of them \rightarrow overhead
- idea: multilevel page tables
  - PRO: less required storage per process
  - CON: amount of actual memory accesses increases with logical accesses

[[/knowledge-database/images/multilevel-page-table.png]]
Average segmenation $= \frac{p}{2}$\\

*Inverted Page Table*\\
- problem: page tables can get large and there can be a lot of them \rightarrow overhead
- idea: only store required entries (\rightarrow inverted page table)
  - /one/ system-wide page table for the entire physical address space
  - table saves the page number /per frame/
  - in case of non-disjunct process address spaces the process-ID gets also stored alongside with the page number
  - independent of of the size of the logical address space \rightarrow scalability
  - requires an efficient searching for the page number when translating an address
    - build hash out of page number
    - table entries with the same hash-value point to each other (Verkettung)

*** Segmentation
- seperating into subregions of different sizes
- no internal but external segmentation
- chunks/subregions of the logical space are called /segments/

Segments are stored and managed similar to pages (but with variable sizes) via a table. Segments can start at arbitrary addresses and the /segment table/ has to store the complete address. Again logical addresses consist of two parts - the segment number and the relative address (offset) inside of the segment. The offset/relative address is added to the base address of an segment to get the complete address.\\
The maximum offset size determines the maximum segment size. This is usually not a problem because the logical address width is larger than the physical, so the segment can encompass the whole physical address space. In contrast to paging, the offset can superseed the wanted segment size so this may require additional guard mechanisms (additions to the segment table are verified/validated byt the MMU).\\
Paging and segmentation are often combined in practise, for example segments that get arranged into pages.

Segment and page tables are stored in primary storage. To compute a physical address, a page and/or segment address entry has to be retrieved first. So there are /two/ memory accesses required per address acess. To speed things up the most recent segment or page entries are stored in a fast register.
- TLB = translation lookaside buffer
- content based addressing (associative storage), search in one step
- typical hit ratio of the TLB is at 99% (locality principle \rightarrow Chapter 07)
